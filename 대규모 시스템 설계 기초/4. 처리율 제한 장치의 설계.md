# 4. 처리율 제한 장치의 설계

## 처리율 제한 장치란?
- 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치이다. 
- Dos 공격에 의한 자원 고갈을 방지할 수 있다. 
- 서버를 많이 두지 않아도 되고, 우선 순위 높은 api에 더 많은 자원을 할당하면 되서 비용이 절감된다.
- 봇, 잘못된 이용 패턴으로 유발된 서버 과부화를 막는다.
<br/>

## 면접
- 면접관과 소통하며 요구사항 파악할 때 하면 좋은 관련 질문
  - 클라이언트 측 or 서버 측 어느 쪽 처리율을 제한할 것인지
  - 호출 제한 규칙
  - 시스템의 규모
  - 분산 환경에서 동작이 필요한지
  - 독립적인 서비스인지 애플리케이션 코드에 포함시킬지
  - 처리율 한도에 걸린 경우 사용자에게 사실을 알려야 하는지
- 처리율 제한 장치를 어디 둘 지 따지기 & 고려 포인트
  - 서버 or api 게이트웨이
  - 프로그래밍 언어가 서버측 구현을 지원할 수 있는지
  - 필요한 처리율 제한 알고리즘 찾기 : 서버측에서 구현한다면 좀 더 자유롭게 고를 수 있다.
  - 회사 서비스가 마이크로 서비스에 기반하고 사용자 인증이나 ip 허용 목록 관리등을 처리하기 위해 api 게이트웨이를 이미 설계에 포함시켰다면 처리율 제한 기능 또한 게이트웨이에 포함시켜야 할 수도 있다.  시간이 없다면 상용 api 게이트웨이 사용이 바람직하다.

질문) 독립 서비스인지?는 왜 물어보지? 장치를 api 서버에 포함할지, 미들웨어로 둘지

<br/>


## 많이 쓰이는 처리율 제한 알고리즘
### **1. 토큰 버킷**
**동작 원리**
- 매초 마다 n개의 토큰이 버킷에 채워진다. 
- 요청이 왔을 때 버킷에 토큰이 충분하면 토큰 1개를 버킷에서 꺼내어 요청을 시스템에 전달한다.
- 만약 요청을 처리할 토큰이 없으면 해당 요청은 버려진다. 
- 버킷에 담을 수 있는 토큰의 최대 개수, 초당 몇개의 토큰이 버킷에 공급되는지 조건이 있다.

**예시**
- 보통 API 엔드포인트마다 버킷을 둔다고 한다.  ex. 하루에 한 번만 포스팅 허용
- 만약 ip 주소별로 처리율을 제한해야 한다면 ip 주소마다 버킷을 두면 된다.
- 만약 시스템 처리율을 초당 10000개로 제한해야 한다면 모든 요청이 하나의 버킷을 공유하도록 하면 된다.

**장점**
- 구현이 쉽고 메모리 사용 측면에서 효율적이라고 한다. 짧은 시간에 집중되는 트래픽도 처리할 수 있다. 버킷에 남은 토큰이 있기만하면 요청은 시스템에 전달된다.

**단점**
- 버킷 크기와 토큰 공급률 조건을 적절히 튜닝하는 것이 어렵다.

질문) 어떤점에서 메모리 사용측면에서 효율적이지?

<br/>

### **2. 누출 버킷**

**동작 원리**
- 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다. 
- 요청이 왔을 때 큐가 비어 있으면 요청을 추가한다.
- 만약 큐가 꽉 차있다면 새 요청은 버린다.
- 큐에 들어 있는 요청은 지정된 시간 마다 꺼내어 처리된다.
- 큐의 사이즈, n 초동안 몇개의 항목을 처리할지(처리율) 조건이 있다. 

**장점**
- 큐의 크기가 제한되어 있어서 메모리 사용량 측면에서 효율적이다. 고정된 처리율을 가지고 있기 때문에 안정적 출력이 필요한 경우에 적합하다. 

질문 및 이해) 토큰 버킷은 고정적 처리율이 아닌가? 아니다. 토큰 버킷은 토큰이 있기만 하면 요청을 보내는데, 누출 버킷은 같은 시간에 같은양의 요청이 처리되기 때문이다.

**단점**
- 단시간에 많은 트래픽이 몰리는 경우 최신 요청들이 버려지게 될 수 있다.
- 버킷 크기와 처리율 조건을 적절히 튜닝하는 것이 어렵다.

질문) 버킷과 큐를 같은 개념으로 봐도 될까?


<br/>

### **3. 고정 윈도 카운터**

**동작 원리**
- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 둔다.
- 요청이 접수되면 해당 윈도의 카운터 값을 1 증가시킨다.
- 해당 카운터의 값이 임계치에 도달하면 이후 요청은 새 윈도(타임라인)이 열릴 때까지 버려진다.

**장점**
- 메모리 효율이 좋다.
- 이해하기 쉽다.
- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기 적합하다.

**단점**
- 카운터가 초기화 되는 윈도 타임라인 경계 부근에서 트래픽이 갑자기 많이 몰리면 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.


질문) 어떤점에서 메모리 효율이 좋지?
질문) 어떤 서비스에서 사용할까? 특정한 트래픽 패턴에 왜 적합하지? 예시가 필요


<br/>


### **4. 이동 윈도 로그**

**동작 원리**
- 고정 윈도 카운터의 단점을 해결한다. 

질문) 어떻게 해결?

- 요청의 타임스탬프를 캐시(레디스 sorted set) 에 보관한다.
- 새 요청이 오면 현재 윈도의 시작점보다 오래된 스탬프는 제거한다.
- 그리고 해당 요청의 타임 스탬프를 로그에 추가한다.
- 캐시에 저장된 로그의 크기가 허용치 이하이면 요청을 시스템에 전달하고 아니면 요청을 전달하지 않고 타임스탬프만 기록한다.

질문) sorted set 알아보기. 제거를 자주해야 하면 캐시를 쓰면 안좋다고 주워들었는데 아닌가?
질문) 현재 윈도의 시작점은 새요청이 왔을때부터 N분인건가? 

 
**장점**
- 어느 순간의 윈도우를 봐도 허용되는 요청의 개수가 처리율 한도를 넘지 않는다. 

질문) 왜지 잘 모르겠다.
질문) 고정, 이동 윈도에서 각각 윈도우 시작, 끝시점 정하는게 달라지는건가??

**단점**
- 거부된 요청의 타임스탬프도 보관하기 때문에 다량의 메모리를 사용한다.

<br/>

### **5. 이동 윈도 카운터**

- 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것
- 현재 윈도에 몇 개의 요청이 왔는 지 계산 법
	= 현재 1분간 요청 수 + 직전 1분간 요청수 * 이동 윈도와 직전 1분이 겹치는 비율
- 계산 값이 처리율 제한 한도를 넘지 않으면 요청이 처리된다.


**장점**
- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
- 메모리 효율이 좋다.

**단점**
- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 값이 정확하지 않을 수 있는데 거의 맞다고 한다.


질문) 그림 4-6 에 분은 뭐지? 1분이 지나서 4개가 채워짐
질문 ) 수강신청 은 어떤 알고리즘?

<br/>

## 개략적인 아키텍처
- 요구사항 : 요청 수를 셀 카운터를 엔드포인트 별로 두고 이 카운터의 값이 한도를 넘으면 이후 요청은 거부한다. 
- 카운터는 캐시가 바람직하다. 디비보다 빠르고 시간에 기반한 만료 정책을 지원하기 때문이다. 
- 처리율 제한 규칙(ex. 분당 로그인 5회 제한)은 보통 설정 파일 형태로 디스크에 저장된다.
- 처리율 한도 제한에 걸리면 api가 429 http 상태 코드와 함께 몇초 뒤 요청 다시 보내야 하는지의 정보를 리턴하거나 해당 메세지를 나중에 처리하기 위해 큐에 보관할 수 있다. 
- http 응답 헤더에 처리율 제한 관련 정보를 담을 수 있다.
	 - x-ratelimit-remaining : 윈도 내 남은 처리 가능 요청 수
	 - x-ratelimit-limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청 수
	 - x-ratelimit-retry-after : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는 지


<br/>


### 아키텍처
	1. 클라이언트가 처리율 제한 미들웨어에게 요청을 보낸다.
	2. 처리율 제한 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와 한도를 체크하고 요청을 api 서버로 전달한다. 또한 카운터의 값을 증가시켜 다시 레디스에 저장한다.
	3. 만약 카운터가 한도를 넘었다면 429 에러를 클라이언트에 보낸다. 클라이언트가 줬던 요청은 큐에 저장하거나 버린다.

<br/>

### 분산 환경에서의 처리율 제한 장치의 구현
- 여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장할 땐 경쟁 조건, 동기화를 고려해야 한다.
- 경쟁 조건
		- 카운터 값을 1이 아닌 증설된 서버의 개수 만큼 값이 증가되어야 함에 주의해야 한다.
		- 락 해결방법은 시스템 성능을 떨어 뜨리므로 대신 루아 스크립트, sorted set 레디스 자료 구조를 통해 경쟁조건 이슈를 해결할 수 있다.
- 동기화 이슈
		- 수백만 사용자를 지원하려면 한 대의 처리율 제한 장치 서버로는 충분치 않을 수 있다. 처리율 제한 장치를 여러 대 둔다면 동기화가 필요하다. 
		- 동일한 클라이언트가 서로 다른 처리율 제한 장치에게 요청을 보내도 동일한 클라이언트의 요청인지 알아볼 수 있어야 한다. 
		- 고정 세션을 활용하여 동일한 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있다. 그러나 규모면에서 확장이 불가능하고 유연하지 않다. 
		- 대신 레디스 같은 중앙 집중형 데이터 저장소를 쓰는 것이다.

질문) 레디스를 중앙 집중형..? 으로 뭘어쩌라는거? 그림 4-16에서 레디스의 기능은?

<br/>

### 성능 최적화
- 처리율 제한 장치에서 여러 데이터 센터를 지원하는 문제는 매우 중요하다. 데이터 센터에서 멀리 떨어진 사용자를 지원하다보면 지연시간이 증가하기 때문이다. 이를 보완하기 위해 에지서버를 두고 사용자의 트래픽을 가장 가까운 에지 서버로 전달하여 지연시간을 줄인다.

질문) 데이터 센터랑 장치랑 무슨 차이..?

- 제한 장치 간에 데이터를 동기화할 때 최종 일관성 모델을 사용해야 한다. 

<br/>

### 모니터링
- 효과적으로 동작하고 있는지 데이터를 모을 필요가 있다. 
- 처리율 제한 규칙이 너무 빡빡해서 많은 요청이 버리지진 않는지
- 채택한 처리율 제한 알고리즘이 비효율 적이진 않은지

<br/>


## 더 알아보면 좋은 개념들
- 경성 처리율 제한 : 요청의 개수는 임계치를 넘을 수 없다.
- 연성 처리율 제한 : 요청 개수는 잠시 동안 임계치를 넘어설 수 있다.
- 다양한 OSI 계층에서의 처리율 제한
- 처리율 제한 회피
		- 클라이언트 측 캐시 사용하여 api 호출 수 줄이기
		- 짧은 시간 동안 너무 많은 메세지 보내지 않기
		- 예외, 에러 코드로 도입하여 클라이언트의 우아한 대응
		- 재시도 로직은 충분한 시간을 두고 한다.
 

	
